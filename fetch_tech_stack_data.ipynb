{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch popular tags data from StackExchange API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "fetch_count = 3000\n",
    "max_page_size = 100\n",
    "tags = []\n",
    "for page in range(1, fetch_count // max_page_size + 1):\n",
    "    response = requests.get(\n",
    "        f'https://api.stackexchange.com/2.3/tags?page={page}&pagesize={max_page_size}&order=desc&sort=popular&site=stackoverflow')\n",
    "    if response.status_code == 200:\n",
    "        tags.extend(response.json()['items'])\n",
    "    time.sleep(1)  # To prevent hitting rate limits\n",
    "\n",
    "\n",
    "tags_df = pd.DataFrame(tags)\n",
    "tags_df.to_csv('tempdata/stach_exchange_tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch synonyms data of popular tags from StackExchange API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from urllib.parse import quote\n",
    "\n",
    "tags_df = pd.read_csv('tempdata/stach_exchange_tags.csv')\n",
    "\n",
    "synonyms = []\n",
    "tags_has_synonyms = tags_df[tags_df['has_synonyms'] == True]\n",
    "chunked_tags = [tags_has_synonyms[i:i + 10] for i in range(0, len(tags_has_synonyms), 10)]\n",
    "for chunk in chunked_tags:\n",
    "    has_next = True\n",
    "    page = 0\n",
    "    joined_tags = quote(';'.join(map(str, chunk['name'].values)))\n",
    "    while has_next:\n",
    "        page += 1\n",
    "        request_url = f'https://api.stackexchange.com/2.3/tags/{joined_tags}/synonyms?pagesize=100&page={page}&order=desc&min=1609459200&sort=activity&site=stackoverflow'\n",
    "        response = requests.get(request_url)\n",
    "        synonyms += [{\n",
    "            \"to_tag\": synonym['to_tag'],\n",
    "            \"from_tag\": synonym['from_tag'],\n",
    "        } for synonym in response.json()['items']]\n",
    "        has_next = response.json()['has_more']\n",
    "        time.sleep(1)  # To prevent hitting rate limits\n",
    "    \n",
    "synonyms_df = pd.DataFrame(synonyms)\n",
    "grouped_synonyms_df = synonyms_df.groupby('to_tag')['from_tag'].apply(list).reset_index(name='synonyms')\n",
    "grouped_synonyms_df.to_csv('tempdata/stack_exchange_tag_synonyms.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch StackShare's tool page site map data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "stackshare_sitemap_url = 'https://stackshare.io/sitemap.xml'\n",
    "response = requests.get(stackshare_sitemap_url)\n",
    "stachshare_sitemap = BeautifulSoup(response.content, 'xml')\n",
    "pattern = re.compile(r'.*tools\\d*\\.xml$')\n",
    "tools_sitemap_urls = [loc.text for loc in stachshare_sitemap.find_all(\n",
    "    'loc') if pattern.match(loc.text)]\n",
    "\n",
    "stackshare_techs = []\n",
    "for url in tools_sitemap_urls:\n",
    "    response = requests.get(url)\n",
    "    tools_sitemap = BeautifulSoup(response.content, 'xml')\n",
    "    stackshare_techs += [\n",
    "        {\n",
    "            'url': loc.text,\n",
    "            'label': loc.text.split('/')[-1],\n",
    "            'unhyphenated_label': loc.text.split('/')[-1].replace('-', ''),\n",
    "        }\n",
    "        for loc in tools_sitemap.find_all('loc')\n",
    "    ]\n",
    "    time.sleep(1)  # To prevent hitting rate limits\n",
    "\n",
    "stackshare_techs_df = pd.DataFrame(stackshare_techs)\n",
    "stackshare_techs_df.to_csv(\n",
    "    'tempdata/stackshare_techs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join synonyms data with popular tags data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tags_df = pd.read_csv('tempdata/stach_exchange_tags.csv')\n",
    "synonyms_df = pd.read_csv('tempdata/stack_exchange_tag_synonyms.csv', converters={'synonyms': eval})\n",
    "tags_with_synonym_df = pd.merge(tags_df, synonyms_df, left_on='name',\n",
    "                   right_on='to_tag', how='left')\n",
    "tags_with_synonym_df['is_valid'] = False\n",
    "tags_with_synonym_df['stackshare_url'] = ''\n",
    "tags_with_synonym_df['stackshare_label'] = ''\n",
    "tags_with_synonym_df['name'] = tags_with_synonym_df['name'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate stackexchange tags with stackshare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "stackshare_techs_df = pd.read_csv('tempdata/stackshare_techs.csv')\n",
    "\n",
    "def find_label_in_stackshare(label: str):\n",
    "    return stackshare_techs_df[(stackshare_techs_df['label'] == label) | (stackshare_techs_df['unhyphenated_label'] == label)]\n",
    "\n",
    "def find_in_stackshare(label: str, synonyms: List[str] = []):\n",
    "    if find_label_in_stackshare(label).shape[0] > 0:\n",
    "        return find_label_in_stackshare(label).iloc[0]\n",
    "    if len(str(tag['name'])) <= 2 and find_label_in_stackshare(f\"{label}-lang\").shape[0] > 0:\n",
    "        return find_label_in_stackshare(f\"{label}-lang\").iloc[0]\n",
    "    if synonyms is not np.nan:\n",
    "        for synonym in synonyms:\n",
    "            if find_label_in_stackshare(synonym).shape[0] > 0:\n",
    "                return find_label_in_stackshare(synonym).iloc[0]\n",
    "\n",
    "for index, tag in tags_with_synonym_df.iterrows():\n",
    "    try:\n",
    "        result = find_in_stackshare(tag['name'], tag['synonyms'])\n",
    "        if result is not None:\n",
    "            tags_with_synonym_df.loc[index, 'is_valid'] = True\n",
    "            tags_with_synonym_df.loc[index, 'stackshare_url'] = result['url']\n",
    "            tags_with_synonym_df.loc[index, 'stackshare_label'] = result['label']\n",
    "    except:\n",
    "        print(tag)\n",
    "        raise\n",
    "\n",
    "tags_with_synonym_df['display_name'] = tags_with_synonym_df['name'].apply(lambda x: x.replace('-', ' '))\n",
    "tags_with_synonym_df[['display_name', 'is_valid', 'count', 'stackshare_url', 'stackshare_label']].to_csv('data/stack_exchange_tags_with_stackshare.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
